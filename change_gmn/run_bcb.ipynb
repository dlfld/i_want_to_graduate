{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24876 4024 3851 29899 130 109\n",
      "allnodes  2205239\n",
      "77535\n",
      "nextsib  True\n",
      "ifedge  True\n",
      "whileedge  True\n",
      "foredge  True\n",
      "blockedge  True\n",
      "nexttoken True\n",
      "nextuse  True\n",
      "9133\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import javalang\n",
    "import javalang.tree\n",
    "import javalang.ast\n",
    "import javalang.util\n",
    "from javalang.ast import Node\n",
    "import torch\n",
    "from anytree import AnyNode, RenderTree\n",
    "#import treelib\n",
    "from anytree import find\n",
    "from createclone_java import getedge_nextsib,getedge_flow,getedge_nextstmt,getedge_nexttoken,getedge_nextuse\n",
    "\n",
    "def get_token(node):\n",
    "    token = ''\n",
    "    #print(isinstance(node, Node))\n",
    "    #print(type(node))\n",
    "    if isinstance(node, str):\n",
    "        token = node\n",
    "    elif isinstance(node, set):\n",
    "        token = 'Modifier'\n",
    "    elif isinstance(node, Node):\n",
    "        token = node.__class__.__name__\n",
    "    #print(node.__class__.__name__,str(node))\n",
    "    #print(node.__class__.__name__, node)\n",
    "    return token\n",
    "def get_child(root):\n",
    "    #print(root)\n",
    "    if isinstance(root, Node):\n",
    "        children = root.children\n",
    "    elif isinstance(root, set):\n",
    "        children = list(root)\n",
    "    else:\n",
    "        children = []\n",
    "\n",
    "    def expand(nested_list):\n",
    "        for item in nested_list:\n",
    "            if isinstance(item, list):\n",
    "                for sub_item in expand(item):\n",
    "                    #print(sub_item)\n",
    "                    yield sub_item\n",
    "            elif item:\n",
    "                #print(item)\n",
    "                yield item\n",
    "    return list(expand(children))\n",
    "def get_sequence(node, sequence):\n",
    "    token, children = get_token(node), get_child(node)\n",
    "    sequence.append(token)\n",
    "    #print(len(sequence), token)\n",
    "    for child in children:\n",
    "        get_sequence(child, sequence)\n",
    "\n",
    "def getnodes(node,nodelist):\n",
    "    nodelist.append(node)\n",
    "    children = get_child(node)\n",
    "    for child in children:\n",
    "        getnodes(child,nodelist)\n",
    "\n",
    "def createtree(root,node,nodelist,parent=None):\n",
    "    id = len(nodelist)\n",
    "    #print(id)\n",
    "    token, children = get_token(node), get_child(node)\n",
    "    if id==0:\n",
    "        root.token=token\n",
    "        root.data=node\n",
    "    else:\n",
    "        newnode=AnyNode(id=id,token=token,data=node,parent=parent)\n",
    "    nodelist.append(node)\n",
    "    for child in children:\n",
    "        if id==0:\n",
    "            createtree(root,child, nodelist, parent=root)\n",
    "        else:\n",
    "            createtree(root,child, nodelist, parent=newnode)\n",
    "def getnodeandedge_astonly(node,nodeindexlist,vocabdict,src,tgt):\n",
    "    token=node.token\n",
    "    nodeindexlist.append([vocabdict[token]])\n",
    "    for child in node.children:\n",
    "        src.append(node.id)\n",
    "        tgt.append(child.id)\n",
    "        src.append(child.id)\n",
    "        tgt.append(node.id)\n",
    "        getnodeandedge_astonly(child,nodeindexlist,vocabdict,src,tgt)\n",
    "def getnodeandedge(node,nodeindexlist,vocabdict,src,tgt,edgetype):\n",
    "    token=node.token\n",
    "    nodeindexlist.append([vocabdict[token]])\n",
    "    for child in node.children:\n",
    "        src.append(node.id)\n",
    "        tgt.append(child.id)\n",
    "        edgetype.append([0])\n",
    "        src.append(child.id)\n",
    "        tgt.append(node.id)\n",
    "        edgetype.append([0])\n",
    "        getnodeandedge(child,nodeindexlist,vocabdict,src,tgt,edgetype)\n",
    "\n",
    "def countnodes(node,ifcount,whilecount,forcount,blockcount):\n",
    "    token=node.token\n",
    "    if token=='IfStatement':\n",
    "        ifcount+=1\n",
    "    if token=='WhileStatement':\n",
    "        whilecount+=1\n",
    "    if token=='ForStatement':\n",
    "        forcount+=1\n",
    "    if token=='BlockStatement':\n",
    "        blockcount+=1\n",
    "    print(ifcount,whilecount,forcount,blockcount)\n",
    "    for child in node.children:\n",
    "        countnodes(child,ifcount,whilecount,forcount,blockcount)\n",
    "'''def getedge_nextsib(node,vocabdict,src,tgt,edgetype):\n",
    "    token=node.token\n",
    "    for i in range(len(node.children)-1):\n",
    "        src.append(node.children[i].id)\n",
    "        tgt.append(node.children[i+1].id)\n",
    "        edgetype.append([1])\n",
    "        src.append(node.children[i+1].id)\n",
    "        tgt.append(node.children[i].id)\n",
    "        edgetype.append([1])\n",
    "    for child in node.children:\n",
    "        getedge_nextsib(child,vocabdict,src,tgt,edgetype)'''\n",
    "def createast():\n",
    "    asts=[]\n",
    "    paths=[]\n",
    "    alltokens=[]\n",
    "    dirname = 'BCB/bigclonebenchdata/'\n",
    "    for rt, dirs, files in os.walk(dirname):\n",
    "        for file in files:\n",
    "            programfile=open(os.path.join(rt,file),encoding='utf-8')\n",
    "            #print(os.path.join(rt,file))\n",
    "            programtext=programfile.read()\n",
    "            #programtext=programtext.replace('\\r','')\n",
    "            programtokens=javalang.tokenizer.tokenize(programtext)\n",
    "            #print(list(programtokens))\n",
    "            parser=javalang.parse.Parser(programtokens)\n",
    "            programast=parser.parse_member_declaration()\n",
    "            paths.append(os.path.join(rt,file))\n",
    "            asts.append(programast)\n",
    "            get_sequence(programast,alltokens)\n",
    "            programfile.close()\n",
    "            #print(programast)\n",
    "            #print(alltokens)\n",
    "    astdict=dict(zip(paths,asts))\n",
    "    ifcount=0\n",
    "    whilecount=0\n",
    "    forcount=0\n",
    "    blockcount=0\n",
    "    docount = 0\n",
    "    switchcount = 0\n",
    "    for token in alltokens:\n",
    "        if token=='IfStatement':\n",
    "            ifcount+=1\n",
    "        if token=='WhileStatement':\n",
    "            whilecount+=1\n",
    "        if token=='ForStatement':\n",
    "            forcount+=1\n",
    "        if token=='BlockStatement':\n",
    "            blockcount+=1\n",
    "        if token=='DoStatement':\n",
    "            docount+=1\n",
    "        if token=='SwitchStatement':\n",
    "            switchcount+=1\n",
    "    print(ifcount,whilecount,forcount,blockcount,docount,switchcount)\n",
    "    print('allnodes ',len(alltokens))\n",
    "    alltokens=list(set(alltokens))\n",
    "    vocabsize = len(alltokens)\n",
    "    tokenids = range(vocabsize)\n",
    "    vocabdict = dict(zip(alltokens, tokenids))\n",
    "    print(vocabsize)\n",
    "    return astdict,vocabsize,vocabdict\n",
    "\n",
    "def createseparategraph(astdict,vocablen,vocabdict,device,mode='astonly',nextsib=False,ifedge=False,whileedge=False,foredge=False,blockedge=False,nexttoken=False,nextuse=False):\n",
    "    pathlist=[]\n",
    "    treelist=[]\n",
    "    print('nextsib ',nextsib)\n",
    "    print('ifedge ',ifedge)\n",
    "    print('whileedge ',whileedge)\n",
    "    print('foredge ',foredge)\n",
    "    print('blockedge ',blockedge)\n",
    "    print('nexttoken', nexttoken)\n",
    "    print('nextuse ',nextuse)\n",
    "    print(len(astdict))\n",
    "    for path,tree in astdict.items():\n",
    "        #print(tree)\n",
    "        #print(path)\n",
    "        nodelist = []\n",
    "        newtree=AnyNode(id=0,token=None,data=None)\n",
    "        createtree(newtree, tree, nodelist)\n",
    "        #print(path)\n",
    "        #print(newtree)\n",
    "        x = []\n",
    "        edgesrc = []\n",
    "        edgetgt = []\n",
    "        edge_attr=[]\n",
    "        if mode=='astonly':\n",
    "            getnodeandedge_astonly(newtree, x, vocabdict, edgesrc, edgetgt)\n",
    "        else:\n",
    "            getnodeandedge(newtree, x, vocabdict, edgesrc, edgetgt,edge_attr)\n",
    "            if nextsib==True:\n",
    "                getedge_nextsib(newtree,vocabdict,edgesrc,edgetgt,edge_attr)\n",
    "            getedge_flow(newtree,vocabdict,edgesrc,edgetgt,edge_attr,ifedge,whileedge,foredge)\n",
    "            if blockedge==True:\n",
    "                getedge_nextstmt(newtree,vocabdict,edgesrc,edgetgt,edge_attr)\n",
    "            tokenlist=[]\n",
    "            if nexttoken==True:\n",
    "                getedge_nexttoken(newtree,vocabdict,edgesrc,edgetgt,edge_attr,tokenlist)\n",
    "            variabledict={}\n",
    "            if nextuse==True:\n",
    "                getedge_nextuse(newtree,vocabdict,edgesrc,edgetgt,edge_attr,variabledict)\n",
    "        #x = torch.tensor(x, dtype=torch.long, device=device)\n",
    "        edge_index=[edgesrc, edgetgt]\n",
    "        #edge_index = torch.tensor([edgesrc, edgetgt], dtype=torch.long, device=device)\n",
    "        astlength=len(x)\n",
    "        #print(x)\n",
    "        #print(edge_index)\n",
    "        #print(edge_attr)\n",
    "        pathlist.append(path)\n",
    "        treelist.append([[x,edge_index,edge_attr],astlength])\n",
    "        astdict[path]=[[x,edge_index,edge_attr],astlength]\n",
    "    #treedict=dict(zip(pathlist,treelist))\n",
    "    #print(totalif,totalwhile,totalfor,totalblock)\n",
    "    return astdict\n",
    "def creategmndata(id,treedict,vocablen,vocabdict,device):\n",
    "    indexdir='BCB/'\n",
    "    if id=='0':\n",
    "        trainfile = open(indexdir+'traindata.txt')\n",
    "        validfile = open(indexdir+'devdata.txt')\n",
    "        testfile = open(indexdir+'testdata.txt')\n",
    "    elif id=='11':\n",
    "        trainfile = open(indexdir+'traindata11.txt')\n",
    "        validfile = open(indexdir+'devdata.txt')\n",
    "        testfile = open(indexdir+'testdata.txt')\n",
    "    else:\n",
    "        print('file not exist')\n",
    "        quit()\n",
    "    trainlist=trainfile.readlines()\n",
    "    validlist=validfile.readlines()\n",
    "    testlist=testfile.readlines()\n",
    "    traindata=[]\n",
    "    validdata=[]\n",
    "    testdata=[]\n",
    "    print('train data')\n",
    "    traindata=createpairdata(treedict,trainlist,device=device)\n",
    "    print('valid data')\n",
    "    validdata=createpairdata(treedict,validlist,device=device)\n",
    "    print('test data')\n",
    "    testdata=createpairdata(treedict,testlist,device=device)\n",
    "    return traindata, validdata, testdata\n",
    "def createpairdata(treedict,pathlist,device):\n",
    "    datalist=[]\n",
    "    countlines=1\n",
    "    for line in pathlist:\n",
    "        #print(countlines)\n",
    "        countlines += 1\n",
    "        pairinfo = line.split()\n",
    "        code1path='BCB'+pairinfo[0].strip('.')\n",
    "        code2path='BCB'+pairinfo[1].strip('.')\n",
    "        label=int(pairinfo[2])\n",
    "        data1 = treedict[code1path]\n",
    "        data2 = treedict[code2path]\n",
    "        x1,edge_index1,edge_attr1,ast1length=data1[0][0],data1[0][1],data1[0][2],data1[1]\n",
    "        x2,edge_index2,edge_attr2,ast2length=data2[0][0],data2[0][1],data2[0][2],data2[1]\n",
    "        '''matchsrc = []\n",
    "        matchtgt = []\n",
    "        for i in range(ast1length):\n",
    "            for j in range(ast2length):\n",
    "                matchsrc.append(i)\n",
    "                matchtgt.append(j)\n",
    "        match_index=[matchsrc, matchtgt]'''\n",
    "        #match_index = torch.tensor([matchsrc, matchtgt], dtype=torch.long, device=device)\n",
    "        if edge_attr1==[]:\n",
    "            edge_attr1 = None\n",
    "            edge_attr2 = None\n",
    "        data = [[x1, x2, edge_index1, edge_index2, edge_attr1, edge_attr2], label]\n",
    "        datalist.append(data)\n",
    "    return datalist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    astdict, vocabsize, vocabdict=createast()\n",
    "    treedict=createseparategraph(astdict, vocabsize, vocabdict,device='cpu',mode='else',nextsib=True,ifedge=True,whileedge=True,foredge=True,blockedge=True,nexttoken=True,nextuse=True)\n",
    "    #creategmndata(treedict,vocabsize,vocabdict,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24876 4024 3851 29899 130 109\n",
      "allnodes  2205239\n",
      "77535\n",
      "nextsib  True\n",
      "ifedge  True\n",
      "whileedge  True\n",
      "foredge  /home/dlf/.local/share/jupyter/runtime/kernel-v2-1557584OalcKDqK77sO.json\n",
      "blockedge  True\n",
      "nexttoken True\n",
      "nextuse  True\n",
      "9133\n",
      "train data\n",
      "valid data\n",
      "test data\n",
      "450862\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  29%|██▉       | 4056/14090 [58:15<2:24:07,  1.16it/s]\n",
      "Epoch (Loss=0.00061):   0%|          | 0/10 [58:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 174\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m# plt.figure(figsize=(10,10),dpi=150)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m train_loss_lines \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mplot(x, loss_list, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, lw\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m#lw为曲线宽度\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m plt\u001b[39m.\u001b[39;49mpause(\u001b[39m0.1\u001b[39;49m) \u001b[39m#图片停留0.1s\u001b[39;00m\n\u001b[1;32m    176\u001b[0m totalloss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\n\u001b[1;32m    177\u001b[0m main_index \u001b[39m=\u001b[39m main_index \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/pyplot.py:581\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[39mif\u001b[39;00m canvas\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mstale:\n\u001b[1;32m    580\u001b[0m         canvas\u001b[39m.\u001b[39mdraw_idle()\n\u001b[0;32m--> 581\u001b[0m     show(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    582\u001b[0m     canvas\u001b[39m.\u001b[39mstart_event_loop(interval)\n\u001b[1;32m    583\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m figure_manager \u001b[39min\u001b[39;00m Gcf\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         display(\n\u001b[1;32m     91\u001b[0m             figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure,\n\u001b[1;32m     92\u001b[0m             metadata\u001b[39m=\u001b[39;49m_fetch_figure_metadata(figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure)\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[39m.\u001b[39m_to_draw \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/IPython/core/formatters.py:177\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    175\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/IPython/core/formatters.py:221\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/IPython/core/formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    340\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/backend_bases.py:2342\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2337\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2338\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2339\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2340\u001b[0m     )\n\u001b[1;32m   2341\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2342\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/figure.py:3140\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3140\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3141\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3143\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3144\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/axes/_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[39mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3062\u001b[0m     _draw_rasterized(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3064\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3065\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3067\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/axis.py:1380\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m tlb1, tlb2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   1379\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m-> 1380\u001b[0m     tick\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   1382\u001b[0m \u001b[39m# Shift label away from axes to avoid overlapping ticklabels.\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_label_position(renderer)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/axis.py:301\u001b[0m, in \u001b[0;36mTick.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    298\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[1;32m    299\u001b[0m \u001b[39mfor\u001b[39;00m artist \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgridline, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick1line, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick2line,\n\u001b[1;32m    300\u001b[0m                \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel2]:\n\u001b[0;32m--> 301\u001b[0m     artist\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    302\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/text.py:752\u001b[0m, in \u001b[0;36mText.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    749\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[1;32m    751\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cm_set(text\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_wrapped_text()):\n\u001b[0;32m--> 752\u001b[0m     bbox, info, descent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_layout(renderer)\n\u001b[1;32m    753\u001b[0m     trans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_transform()\n\u001b[1;32m    755\u001b[0m     \u001b[39m# don't use self.get_position here, which refers to text\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39m# position in Text:\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn_ast_flow/lib/python3.8/site-packages/matplotlib/text.py:510\u001b[0m, in \u001b[0;36mText._get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    507\u001b[0m bbox \u001b[39m=\u001b[39m Bbox\u001b[39m.\u001b[39mfrom_bounds(xmin, ymin, width, height)\n\u001b[1;32m    509\u001b[0m \u001b[39m# now rotate the positions around the first (x, y) position\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m xys \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39;49mtransform(offset_layout) \u001b[39m-\u001b[39;49m (offsetx, offsety)\n\u001b[1;32m    512\u001b[0m \u001b[39mreturn\u001b[39;00m bbox, \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(lines, \u001b[39mzip\u001b[39m(ws, hs), \u001b[39m*\u001b[39mxys\u001b[39m.\u001b[39mT)), descent\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display\n",
    "import sys\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "import pycparser\n",
    "# from createclone_bcb import createast,creategmndata,createseparategraph\n",
    "import models\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--cuda\", default=True)\n",
    "parser.add_argument(\"--dataset\", default='gcj')\n",
    "parser.add_argument(\"--graphmode\", default='astandnext')\n",
    "parser.add_argument(\"--nextsib\", default=True)\n",
    "parser.add_argument(\"--ifedge\", default=True)\n",
    "parser.add_argument(\"--whileedge\", default=True)\n",
    "parser.add_argument(\"--foredge\", default=True)\n",
    "parser.add_argument(\"--blockedge\", default=True)\n",
    "parser.add_argument(\"--nexttoken\", default=True)\n",
    "parser.add_argument(\"--nextuse\", default=True)\n",
    "parser.add_argument(\"--data_setting\", default='11')\n",
    "parser.add_argument(\"--batch_size\", default=32)\n",
    "parser.add_argument(\"--num_layers\", default=4)\n",
    "parser.add_argument(\"--num_epochs\", default=10)\n",
    "parser.add_argument(\"--lr\", default=0.001)\n",
    "parser.add_argument(\"--threshold\", default=0)\n",
    "args = parser.parse_known_args()[0]\n",
    " \n",
    "device=torch.device('cuda:0')\n",
    "#device=torch.device('cpu')\n",
    "astdict,vocablen,vocabdict=createast()\n",
    "treedict=createseparategraph(astdict, vocablen, vocabdict,device,mode=args.graphmode,nextsib=args.nextsib,ifedge=args.ifedge,whileedge=args.whileedge,foredge=args.foredge,blockedge=args.blockedge,nexttoken=args.nexttoken,nextuse=args.nextuse)\n",
    "traindata,validdata,testdata=creategmndata(args.data_setting,treedict,vocablen,vocabdict,device)\n",
    "print(len(traindata))\n",
    "#trainloder=DataLoader(traindata,batch_size=1)\n",
    "num_layers=int(args.num_layers)\n",
    "model=models.GMNnet(vocablen,embedding_dim=100,num_layers=num_layers,device=device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion=nn.CosineEmbeddingLoss()\n",
    "criterion2=nn.MSELoss()\n",
    "criterion3 = torch.nn.BCEWithLogitsLoss()\n",
    "def create_batches(data):\n",
    "    #random.shuffle(data)\n",
    "    batches = [data[graph:graph+args.batch_size] for graph in range(0, len(data), args.batch_size)]\n",
    "    return batches\n",
    "\n",
    "def test(dataset):\n",
    "    #model.eval()\n",
    "    count=0\n",
    "    correct=0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    results=[]\n",
    "    for data,label in dataset:\n",
    "        label=torch.tensor(label, dtype=torch.float, device=device)\n",
    "        x1, x2, edge_index1, edge_index2, edge_attr1, edge_attr2=data\n",
    "        x1=torch.tensor(x1, dtype=torch.long, device=device)\n",
    "        x2=torch.tensor(x2, dtype=torch.long, device=device)\n",
    "        edge_index1=torch.tensor(edge_index1, dtype=torch.long, device=device)\n",
    "        edge_index2=torch.tensor(edge_index2, dtype=torch.long, device=device)\n",
    "        if edge_attr1!=None:\n",
    "            edge_attr1=torch.tensor(edge_attr1, dtype=torch.long, device=device)\n",
    "            edge_attr2=torch.tensor(edge_attr2, dtype=torch.long, device=device)\n",
    "        data=[x1, x2, edge_index1, edge_index2, edge_attr1, edge_attr2]\n",
    "        prediction=model(data)\n",
    "        output=F.cosine_similarity(prediction[0],prediction[1])\n",
    "        results.append(output.item())\n",
    "        prediction = torch.sign(output).item()\n",
    "\n",
    "        if prediction>args.threshold and label.item()==1:\n",
    "            tp+=1\n",
    "            #print('tp')\n",
    "        if prediction<=args.threshold and label.item()==-1:\n",
    "            tn+=1\n",
    "            #print('tn')\n",
    "        if prediction>args.threshold and label.item()==-1:\n",
    "            fp+=1\n",
    "            #print('fp')\n",
    "        if prediction<=args.threshold and label.item()==1:\n",
    "            fn+=1\n",
    "            #print('fn')\n",
    "    print(tp,tn,fp,fn)\n",
    "    p=0.0\n",
    "    r=0.0\n",
    "    f1=0.0\n",
    "    if tp+fp==0:\n",
    "        print('precision is none')\n",
    "        return\n",
    "    p=tp/(tp+fp)\n",
    "    if tp+fn==0:\n",
    "        print('recall is none')\n",
    "        return\n",
    "    r=tp/(tp+fn)\n",
    "    f1=2*p*r/(p+r)\n",
    "    print('precision')\n",
    "    print(p)\n",
    "    print('recall')\n",
    "    print(r)\n",
    "    print('F1')\n",
    "    print(f1)\n",
    "    return results\n",
    "\n",
    "loss_list = []\n",
    "x = []\n",
    "plt.title(\"loss\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"train_loss\"])\n",
    "plt.ylim(3-0.000001,-3+0.000001)\n",
    "epochs = trange(args.num_epochs, leave=True, desc = \"Epoch\")\n",
    "for epoch in epochs:# without batching\n",
    "    print(epoch)\n",
    "    batches=create_batches(traindata)\n",
    "    totalloss=0.0\n",
    "    main_index=0.0\n",
    "    for index, batch in tqdm(enumerate(batches), total=len(batches), desc = \"Batches\"):\n",
    "        optimizer.zero_grad()\n",
    "        batchloss= 0\n",
    "\n",
    "        for data,label in batch:\n",
    "            label =  [0] if label == [-1] else [1]\n",
    "            label=torch.tensor(label, dtype=torch.float, device=device)\n",
    "            label=torch.unsqueeze(label,dim=0)\n",
    "            #print(len(data))\n",
    "            #for i in range(len(data)):\n",
    "                #print(i)\n",
    "                #data[i]=torch.tensor(data[i], dtype=torch.long, device=device)\n",
    "            x1, x2, edge_index1, edge_index2, edge_attr1, edge_attr2=data\n",
    "            x1=torch.tensor(x1, dtype=torch.long, device=device)\n",
    "            x2=torch.tensor(x2, dtype=torch.long, device=device)\n",
    "\n",
    "            edge_index1=torch.tensor(edge_index1, dtype=torch.long, device=device)\n",
    "            edge_index2=torch.tensor(edge_index2, dtype=torch.long, device=device)\n",
    "            if edge_attr1!=None:\n",
    "                edge_attr1=torch.tensor(edge_attr1, dtype=torch.long, device=device)\n",
    "                edge_attr2=torch.tensor(edge_attr2, dtype=torch.long, device=device)\n",
    "\n",
    "            data=[x1, x2, edge_index1, edge_index2, edge_attr1, edge_attr2]\n",
    "\n",
    "            logits=model(data)\n",
    "            # print(f\"logits={logits},label={label}\")\n",
    "            \n",
    "            batchloss += criterion3(logits, label)  # -log(sigmoid(1.5))\n",
    "\n",
    "\n",
    "            # batchloss=batchloss+criterion(prediction[0],prediction[1],label)\n",
    "            # cossim=F.cosine_similarity(prediction[0],prediction[1])\n",
    "            # batchloss=batchloss+criterion2(cossim,label)\n",
    "\n",
    "        batchloss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        loss = batchloss.item()\n",
    "        loss_list.append(loss)\n",
    "        x.append(epoch*len(batches)+index)\n",
    "      \n",
    "        display.clear_output(wait=True)\n",
    "        # plt.figure(figsize=(10,10),dpi=150)\n",
    "        train_loss_lines = plt.plot(x, loss_list, 'r', lw=1)#lw为曲线宽度\n",
    "        \n",
    "\n",
    "        plt.pause(0.1) #图片停留0.1s\n",
    "        \n",
    "        totalloss+=loss\n",
    "        main_index = main_index + len(batch)\n",
    "        loss=totalloss/main_index\n",
    "        epochs.set_description(\"Epoch (Loss=%g)\" % round(loss,5))\n",
    "\n",
    "# import joblib\n",
    "# joblib.dump(\"loss_data.data\",loss_list)\n",
    "    #test(validdata)\n",
    "\n",
    "    # devresults=test(validdata)\n",
    "    # devfile=open('gmnbcbresult/'+args.graphmode+'_dev_epoch_'+str(epoch+1),mode='w')\n",
    "    # for res in devresults:\n",
    "    #     devfile.write(str(res)+'\\n')\n",
    "    # devfile.close()\n",
    "    # testresults=test(testdata)\n",
    "    # resfile=open('gmnbcbresult/'+args.graphmode+'_epoch_'+str(epoch+1),mode='w')\n",
    "    # for res in testresults:\n",
    "    #     resfile.write(str(res)+'\\n')\n",
    "    # resfile.close()\n",
    "\n",
    "    #torch.save(model,'gmnmodels/gmnbcb'+str(epoch+1))\n",
    "    #for start in range(0, len(traindata), args.batch_size):\n",
    "        #batch = traindata[start:start+args.batch_size]\n",
    "        #epochs.set_description(\"Epoch (Loss=%g)\" % round(loss,5))\n",
    "\n",
    "\n",
    "'''for batch in trainloder:\n",
    "    batch=batch.to(device)\n",
    "    print(batch)\n",
    "    quit()\n",
    "    time_start=time.time()\n",
    "    model.forward(batch)\n",
    "    time_end=time.time()\n",
    "    print(time_end-time_start)\n",
    "    quit()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_ast_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
